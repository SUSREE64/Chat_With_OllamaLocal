# Chat_With_OllamaLocal
Streamlit application that runs a locally running Ollama LLMs for Question answer and chatting. 
